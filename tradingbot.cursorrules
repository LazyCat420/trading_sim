Trading Bot Rules:

Give the bot $10,000 starting capital. Also it still failed to toggle automated trading. I think the issue is it needs data to start looking at so have it start scraping the data in the market data tab since the watchlist I have will at least be a control so the bot starts off with those stocks. Have it so the bot can also pick more stocks and brainstom stocks to research based on the news it finds. also have the bot check the news thru the searxng pipeline we made so it can start there for stock market news along with the watchlist. 

# Core Architecture
1. System Foundation:
   - Local LLM Orchestrator: Ollama with llama3.2:latest model
   - Tool Calling Framework: Custom implementation using LangChain's new tools standard
   - Chat History Management: Session-based conversation tracking with context retention

# Conversation Context Management
2. Chat History Features:
   - Session Management:
     • Unique session IDs for each trading conversation
     • Persistent context across multiple interactions
     • Maximum 10 messages per session for focused context
   - Context Integration:
     • Previous trading decisions are referenced
     • Market analysis continuity
     • Strategy consistency enforcement
   - Memory Management:
     • In-memory storage for development
     • Upgradeable to Redis/Database for production
     • Automatic context pruning for relevance

# Strategy Switching Mechanism
3. Investment Philosophy Matrix:
   - Value Investing (Graham/Buffett):
     • Parameters: P/E < 15, P/B < 1.5, D/E < 0.3
     • Holding Period: 3-5 year minimum
   - Growth Hunting (Lynch):
     • Parameters: EPS Growth > 25%, ROE > 15%
     • Sector Focus: Consumer cyclical/Technology
   - Quantitative Edge (Simons):
     • Statistical Arbitrage thresholds
     • Hidden Markov Models for regime detection

# Algorithm Stack
4. Hybrid Analysis Engines:
   - Fundamental Analysis:
     • Custom DCF model with Monte Carlo simulations
     • Sentiment parsing of earnings calls (whisper.cpp local transcribe)
   - Technical Synthesis:
     • Fractal Adaptive Moving Averages (FRAMA)
     • Volume-Weighted MACD variant
   - Machine Learning Layer:
     • LSTM price prediction (PyTorch)
     • SHAP values for feature importance

# Tool Calling Integration
5. Local LLM Tool Registry:
   - Chat Tools:
     • get_chat_history(session_id) -> List[Message]
     • update_chat_history(session_id, message)
     • clear_chat_history(session_id)
   - Data Tools:
     • live_market_scan(sectors, filters)
     • historical_pattern_match(ticker, years)
     • options_chain_analysis(ticker, expiration)
   - Scraping Tools:
     • sec_filings_scraper(ticker, filing_type) - Playwright-based
     • news_sentiment_scraper(query) - Using BeautifulSoup/Playwright
     • social_media_scraper(ticker) - Reddit/Twitter via Scrapy
     • ecommerce_scraper(product_keywords) - Playwright headless browser
   - Analysis Tools:
     • calculate_enterprise_value(ticker)
     • run_scenario_analysis(model_params)
     • crypto_onchain_analysis(wallet_address)
   - Execution Tools:
     • execute_pair_trade(long_ticker, short_ticker)
     • adjust_portfolio_hedge(risk_level)
     • dark_pool_order(routing_strategy)
   - Decision Tools:
     • query_classifier(input_text) -> Type:
       1. News detection using keyword matching
       2. History requests using intent recognition
       3. Fallback to general search
     • integrated_chat_handler(session_id, message) -> Response:
       1. Call query_classifier()
       2. Route to appropriate workflow
       3. Maintain context chain
   - Scheduling Tools:
     • create_price_alert(ticker, target_price)
     • schedule_limit_order(ticker, price, quantity)
     • set_stop_loss(ticker, trigger_price)
     • pattern_recognition_watchlist(symbols)

# Risk Management
6. Capital Preservation Rules:
   - Position Sizing:
     • Kelly Criterion implementation
     • Dynamic correlation adjustment
   - Circuit Breakers:
     • Volatility shutdown (VIX > 35)
     • Drawdown limits (-7% daily/-15% weekly)
   - Black Swan Protection:
     • Tail risk hedging with VIX options
     • Bitcoin correlation breaker

# Adaptive Learning
7. Feedback Mechanisms:
   - Post-Trade Analysis:
     • Win/loss attribution reporting
     • Strategy drift detection
   - Model Retraining:
     • Weekly fundamental model updates
     • Daily technical pattern recalibration
     • Monthly regime classification refresh

# Data Infrastructure
8. Pipeline Architecture:
   - Scraping Framework:
     • Playwright cluster for parallel scraping
     • Rotating residential proxies (BrightData/Oxylabs)
     • CAPTCHA solving integration
   - Data Processing:
     • Pandas 2.0 with Arrow backend
     • dbt for data transformation
     • Great Expectations for validation
   - Storage:
     • Parquet for fundamental data
     • TimescaleDB for time-series
     • Neo4j for market relationships

# State Management
9. Event-Driven Architecture:
   - Trigger Engine:
     • Price-based triggers (support for technical levels)
     • News sentiment thresholds
     • Volume spike detector
     • Correlation break alerts
   - Task Scheduler:
     • Celery for distributed task queue
     • Redis for state persistence
     • Circuit breaker pattern implementation

# Required Stack
- Scraping: Playwright, Scrapy, BeautifulSoup4
- Data: Pandas 2.0, PyArrow, DuckDB
- Async: AnyIO, HTTPX
- ML: Sklearn, XGBoost, LightGBM
- APIs: FastAPI for internal tool calling interface
- Scheduling: Celery + Redis
- State Storage: SQLModel + RedisJSON
- Event Monitoring: Websockets + Apache Kafka

@tool
def news_analysis_workflow(ticker: str) -> dict:
    """Orchestrates news analysis pipeline"""
    articles = news_sentiment_scraper(ticker)
    analysis = sentiment_analysis(articles)
    return generate_trade_plan(
        ticker=ticker,
        sentiment_score=analysis['score'],
        confidence=analysis['confidence']
    )

class TriggerManager:
    def __init__(self):
        self.active_triggers = {}
        
    def add_trigger(self, condition_type: str, params: dict):
        trigger_id = uuid4()
        self.active_triggers[trigger_id] = {
            'condition': condition_type,
            'params': params,
            'status': 'armed'
        }
        return trigger_id

class PaperTradingEngine:
    def __init__(self, initial_balance=10000):
        self.initial_balance = initial_balance
        self.portfolio = defaultdict(float)
        self.cash = initial_balance
        self.order_history = []
        
    def set_initial_balance(self, new_balance):
        """UI-facing method to adjust starting capital"""
        self.initial_balance = new_balance
        self.reset_portfolio()
        
    def reset_portfolio(self):
        """Reset to initial configuration"""
        self.portfolio.clear()
        self.cash = self.initial_balance
        self.order_history = []

    def execute_mock_order(self, order_type: str, ticker: str, 
                         quantity: float, price: float):
        # Simulates order execution with random slippage
        executed_price = price * (1 + np.random.uniform(-0.0005, 0.0005))
        cost = executed_price * quantity
        
        if order_type == 'buy' and self.cash >= cost:
            self.portfolio[ticker] += quantity
            self.cash -= cost
        elif order_type == 'sell':
            self.portfolio[ticker] -= quantity
            self.cash += cost
            
        self.order_history.append({
            'timestamp': datetime.now(),
            'ticker': ticker,
            'type': order_type,
            'quantity': quantity,
            'price': executed_price
        })

# Example UI control flow
engine = PaperTradingEngine()
engine.set_initial_balance(15000)  # User changes via UI
engine.reset_portfolio()  # Reset to new balance
